{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseult = requests.post(reset,headers=headers)\n",
    "reseult.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of moves\n",
    "obsers = []\n",
    "\n",
    "# Set up the logger\n",
    "log_filename = \"maze_agent_run.log\"  \n",
    "\n",
    "try:\n",
    "    if os.path.exists(log_filename):\n",
    "        os.remove(log_filename)\n",
    "except:\n",
    "    pass\n",
    "# Set the logging level for urllib3 to WARNING\n",
    "urllib3_logger = logging.getLogger(\"urllib3\")\n",
    "urllib3_logger.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the logging level\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",  # Format for log messages\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),  # Log to a file\n",
    "        #logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "def get_info(response):\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error code at response\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Retrieve JSON data from response\n",
    "    data = response.json()\n",
    "\n",
    "    # Use .get() method with default to None for each field\n",
    "    done = data.get('done', None)\n",
    "    info = data.get('info', None)\n",
    "    observation = data.get('observation', None)\n",
    "    reward = data.get('reward', None)\n",
    "    trunc = data.get('truncated', None)\n",
    "\n",
    "    # Convert observation to numpy array if it's not None\n",
    "    if observation is not None:\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "        obsers.append(observation)  # Assuming obsers is defined elsewhere\n",
    "    else:\n",
    "        observation = None\n",
    "\n",
    "    return done, info, observation, reward, trunc\n",
    "    \n",
    "# implement retry policy\n",
    "@retry(stop=stop_after_attempt(5),wait=wait_exponential(multiplier=1,min=4,max=10))\n",
    "def make_request(url,headers,data=None):\n",
    "    if data:\n",
    "        response = requests.post(url,headers=headers,json=data)\n",
    "    else:\n",
    "        response = requests.post(url,headers=headers)\n",
    "    #raise http error for bad responses\n",
    "    response.raise_for_status()\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    logging.info(f\"Action:{url.split('/')[3]} data {data}, obs: {response.json().get('observation')},reward: {response.json().get('reward')} \")\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "class TrainingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=1):\n",
    "        super(TrainingCallback, self).__init__(verbose)\n",
    "        self.episode_steps = 0\n",
    "        self.episode_rewards = 0\n",
    "        self.episode_lengths = []\n",
    "        self.episode_rewards_list = []\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        # Increment step and reward counters for the current episode\n",
    "        self.episode_steps += 1\n",
    "        self.episode_rewards += self.locals['rewards']# Assuming rewards is a list\n",
    "\n",
    "        # Check if the episode is done\n",
    "        if self.locals['dones'][0]:\n",
    "            # Log the number of steps and reward for the episode\n",
    "            self.episode_lengths.append(self.episode_steps)\n",
    "            self.episode_rewards_list.append(self.episode_rewards)\n",
    "\n",
    "            logging.info(f\"Episode finished - Steps: {self.episode_steps}, Reward: {self.episode_rewards}\")\n",
    "\n",
    "            # Reset for the next episode\n",
    "            self.episode_steps = 0\n",
    "            self.episode_rewards = 0\n",
    "        \n",
    "\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        total_episodes = len(self.episode_lengths)\n",
    "        if total_episodes > 0:\n",
    "            avg_episode_length = sum(self.episode_lengths) / total_episodes\n",
    "            avg_reward_per_episode = sum(self.episode_rewards_list) / total_episodes\n",
    "            logging.info(f\"End of rollout. Total episodes: {total_episodes}, \"\n",
    "                         f\"Average episode length: {avg_episode_length}, \"\n",
    "                         f\"Average reward per episode: {avg_reward_per_episode}\")\n",
    "\n",
    "\n",
    "class MazeAPIEnv(gym.Env):\n",
    "    def __init__(self, api_step_url, headers,api_reset):\n",
    "        super(MazeAPIEnv, self).__init__()\n",
    "        self.headers = headers = {'Content-Type': 'application/json'}\n",
    "        self.api_step_url = api_step_url  # URL for the API step endpoint\n",
    "        self.headers = headers  # Headers for authorization or any other required fields\n",
    "        self.api_reset = api_reset\n",
    "\n",
    "\n",
    "        # Define the action and observation space\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=0, high=4, shape=(2,), dtype=np.float32)  # Observation space\n",
    "\n",
    "        self.current_state = np.array([0.0, 0.0], dtype=np.float32)  # Starting position\n",
    "        self.done = False\n",
    "        \n",
    "        #array to help exploration\n",
    "        self.visited = set()\n",
    "        self.min_reward = -1\n",
    "        self.max_reward = -0.01\n",
    "        \n",
    "    def normalize(self, observation):\n",
    "        \"\"\" Normalize the observation to the range [0, 1]. \"\"\"\n",
    "        return (observation ) / 10 \n",
    "    \n",
    "    def normalize_reward(self,reward):\n",
    "        return (2*(reward-self.min_reward)/(self.max_reward-self.min_reward))-1\n",
    "            \n",
    "    def reset(self,seed=None,**kwargs):\n",
    "       \n",
    "        response = make_request(url=self.api_reset, headers=self.headers)\n",
    "\n",
    "        self.current_state = np.array([0.0, 0.0], dtype=np.float32)\n",
    "        self.done = False\n",
    "        self.visited = set()\n",
    "        \n",
    "        return self.current_state, {}\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Send the action to the API\n",
    "        content = {'action': int(action)}\n",
    "        \n",
    "        response = make_request(url=self.api_step_url, headers=self.headers, data=content)\n",
    "    \n",
    "        if response.status_code !=200 :\n",
    "            print(\"error code in step\")\n",
    "        \n",
    "        # Extract the response data\n",
    "        done,info,raw_observation,reward,truncated = get_info(response)\n",
    "        reward = reward+1\n",
    "        \n",
    "        \n",
    "        if tuple(raw_observation) not in self.visited:\n",
    "            self.visited.add(tuple(raw_observation))\n",
    "        \n",
    "        self.current_state = self.normalize(np.array(raw_observation, dtype=np.float32))\n",
    "        reward = self.normalize_reward(reward)\n",
    "        # Update current state\n",
    "        self.done = done\n",
    "        \n",
    "\n",
    "        #logging.info(f\"Current State = {self.current_state}\")      \n",
    "          \n",
    "        return self.current_state, reward, done,truncated, {}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_maze_position(position, maze_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Function to plot the agent's position in a 5x5 maze.\n",
    "    \n",
    "    Parameters:\n",
    "    - position (tuple): A tuple (x, y) representing the agent's position in the maze.\n",
    "    - maze_size (tuple): The size of the maze (default is (5, 5)).\n",
    "    \"\"\"\n",
    "    # Create a blank 5x5 grid\n",
    "    maze = np.zeros(maze_size)\n",
    "    \n",
    "    # Mark the agent's position with a 1\n",
    "    maze[position[1], position[0]] = 1  # y is row, x is column\n",
    "    \n",
    "    # Plot the maze\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Show the grid lines\n",
    "    ax.set_xticks(np.arange(-0.5, maze_size[0], 1))\n",
    "    ax.set_yticks(np.arange(-0.5, maze_size[1], 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Show the maze as an image\n",
    "    ax.imshow(maze, cmap='Blues', origin='upper')\n",
    "\n",
    "    # Highlight the agent's position\n",
    "    ax.scatter(position[0], position[1], color='red', s=200, label='Agent Position')\n",
    "\n",
    "    # Set the ticks and labels\n",
    "    ax.set_xticklabels(np.arange(0, maze_size[0] + 1))\n",
    "    ax.set_yticklabels(np.arange(0, maze_size[1] + 1))\n",
    "\n",
    "    # Title and legend\n",
    "    ax.set_title(f'Agent Position in {maze_size[0]}x{maze_size[1]} Maze')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    # Invert y-axis to have the origin at the bottom-left corner\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_new_game = \"http://18.185.60.20:5005/new_game\"\n",
    "\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "response = requests.post(api_new_game, headers=headers)\n",
    "uuid = response.json().get('uuid')\n",
    " \n",
    "\n",
    "step = \"http://18.185.60.20:5005/step/\"+uuid  \n",
    "reset = \"http://18.185.60.20:5005/reset/\"+uuid\n",
    "\n",
    "\n",
    "\n",
    "action_seq = [2,1,3,1,1,1,1,1,2,2,2]\n",
    "response = requests.post(reset,headers=headers)\n",
    "observation = response.json().get('observation')  \n",
    "#print(response.text)\n",
    "print(f\"Original observation {observation}\")\n",
    "\n",
    "for action in action_seq:\n",
    "    \n",
    "    content = {'action': int(action)}\n",
    "    response = requests.post(step,headers=headers,json=content)\n",
    "    done,info,observation,reward,trunc = get_info(response)\n",
    "    print(f\"Move: {action}, obs:{observation}, reward:{reward}, done: {done}\")\n",
    "        \n",
    "\n",
    "observation = response.json().get('observation')  \n",
    "print(\"-------------\")\n",
    "print(f\"Observation berore reset {observation}\")\n",
    "\n",
    "\n",
    "response = requests.post(reset,headers=headers)\n",
    "\n",
    "observation = response.json().get('observation')  \n",
    "print(f\"Observation After reset: {observation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Create a directory to store the frames\n",
    "os.makedirs('frames', exist_ok=True)\n",
    "\n",
    "# Create a 10x10 grid\n",
    "grid_size = 10\n",
    "\n",
    "# Define a sequence of positions (2D coordinates)\n",
    "positions = obsers\n",
    "\n",
    "# Generate frames with an index counter\n",
    "for i, (x, y) in enumerate(positions):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-0.5, grid_size - 0.5)\n",
    "    ax.set_ylim(-0.5, grid_size - 0.5)\n",
    "    ax.set_xticks(np.arange(-0.5, grid_size, 1))\n",
    "    ax.set_yticks(np.arange(-0.5, grid_size, 1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Plot the agent's position\n",
    "    ax.plot(x, y, 'ro', markersize=8)  # 'ro' for red circle marker\n",
    "\n",
    "    # Add the frame number as a text annotation in the plot\n",
    "    ax.text(0.05, 0.95, f'Frame: {i}', transform=ax.transAxes, fontsize=12, verticalalignment='top', color='blue')\n",
    "\n",
    "    # Save each frame as a PNG file\n",
    "    plt.savefig(f'frames/frame_{i:03d}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Parameters for saving the video\n",
    "frame_rate = 2  # frames per second (fps)\n",
    "frame_size = (600, 600)  # Size of the output video\n",
    "\n",
    "# Initialize the video writer with the appropriate codec\n",
    "out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), frame_rate, frame_size)\n",
    "\n",
    "# Loop over the saved frames and write them to the video\n",
    "for i in range(len(positions)):\n",
    "    frame = cv2.imread(f'frames/frame_{i:03d}.png')\n",
    "    frame_resized = cv2.resize(frame, frame_size)  # Resize to match the video size\n",
    "    out.write(frame_resized)\n",
    "\n",
    "# Release the video writer\n",
    "out.release()\n",
    "\n",
    "print(\"Video saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http://18.185.60.20:5005/step/\" .split(\"/\")[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
