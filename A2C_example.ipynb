{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import logging\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of moves\n",
    "obsers = []\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "log_filename = \"maze_agent_run.log\"  # Log file name\n",
    "\n",
    "try:\n",
    "    if os.path.exists(log_filename):\n",
    "        os.remove(log_filename)\n",
    "except:\n",
    "    pass\n",
    "# Set the logging level for urllib3 to WARNING\n",
    "urllib3_logger = logging.getLogger(\"urllib3\")\n",
    "urllib3_logger.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the logging level\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",  # Format for log messages\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),  # Log to a file\n",
    "        #logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "def get_info(response):\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error code at response\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Retrieve JSON data from response\n",
    "    data = response.json()\n",
    "\n",
    "    # Use .get() method with default to None for each field\n",
    "    done = data.get('done', None)\n",
    "    info = data.get('info', None)\n",
    "    observation = data.get('observation', None)\n",
    "    reward = data.get('reward', None)\n",
    "    trunc = data.get('trunc', None)\n",
    "\n",
    "    # Convert observation to numpy array if it's not None\n",
    "    if observation is not None:\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "        obsers.append(observation)  # Assuming obsers is defined elsewhere\n",
    "    else:\n",
    "        observation = None\n",
    "\n",
    "    return done, info, observation, reward, trunc\n",
    "    \n",
    "# implement retry policy\n",
    "@retry(stop=stop_after_attempt(5),wait=wait_exponential(multiplier=1,min=4,max=10))\n",
    "def make_request(url,headers,data=None):\n",
    "    if data:\n",
    "        response = requests.post(url,headers=headers,json=data)\n",
    "    else:\n",
    "        response = requests.post(url,headers=headers)\n",
    "    #raise http error for bad responses\n",
    "    response.raise_for_status()\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    logging.info(f\"Action:{url.split('/')[3]} data {data}, obs: {response.json().get('observation')},reward: {response.json().get('reward')} \")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=1):\n",
    "        super(TrainingCallback, self).__init__(verbose)\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        # Log reward and step details\n",
    "        if self.n_calls % 10 == 0:  # Log every 10th step\n",
    "            logging.info(f\"Step: {self.n_calls}, Reward: {self.locals['rewards']}\")\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        # Called at the end of each rollout (i.e., after each epoch)\n",
    "        #logging.info(f\"End of epoch. Total steps: {self.num_timesteps}\")\n",
    "        logging.info(f\"Last rewards: {self.locals['rewards']}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class MazeAPIEnv(gym.Env):\n",
    "    def __init__(self, api_step_url, headers,api_reset):\n",
    "        super(MazeAPIEnv, self).__init__()\n",
    "        self.headers = headers = {'Content-Type': 'application/json'}\n",
    "        self.api_step_url = api_step_url  # URL for the API step endpoint\n",
    "        self.headers = headers  # Headers for authorization or any other required fields\n",
    "        self.api_reset = api_reset\n",
    "\n",
    "\n",
    "        # Define the action and observation space\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        \n",
    "        # For multi-dimensional observations, use Box space\n",
    "        self.observation_space = spaces.Box(low=0, high=4, shape=(2,), dtype=np.float32)  # Observation space\n",
    "\n",
    "        # Normalization parameters\n",
    "        self.obs_low = self.observation_space.low\n",
    "        self.obs_high = self.observation_space.high\n",
    "        self.obs_range = self.obs_high - self.obs_low\n",
    "        \n",
    "        self.current_state = np.array([0.0, 0.0], dtype=np.float32)  # Starting position\n",
    "        self.done = False\n",
    "        \n",
    "    def normalize(self, observation):\n",
    "        \"\"\" Normalize the observation to the range [0, 1]. \"\"\"\n",
    "        return (observation ) / 10 \n",
    "        \n",
    "    def reset(self,seed=None,**kwargs):\n",
    "       \n",
    "        response = make_request(url=self.api_reset, headers=self.headers)\n",
    "\n",
    "        self.current_state = np.array([0.0, 0.0], dtype=np.float32)\n",
    "        self.done = False\n",
    "        \n",
    "        return self.current_state, {}\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Send the action to the API\n",
    "        content = {'action': int(action)}\n",
    "        \n",
    "        response = make_request(url=self.api_step_url, headers=self.headers, data=content)\n",
    "    \n",
    "        if response.status_code !=200 :\n",
    "            print(\"error code in step\")\n",
    "        # Extract the response data\n",
    "  \n",
    "        done,info,raw_observation,reward,truncated = get_info(response)\n",
    "        reward = reward +1\n",
    "        self.current_state = self.normalize(np.array(raw_observation, dtype=np.float32))\n",
    "\n",
    "        # Update current state\n",
    "        self.done = done\n",
    "        \n",
    "\n",
    "        #logging.info(f\"Current State = {self.current_state}\")      \n",
    "          \n",
    "        return self.current_state, reward, done, {}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************RANDOM AGENT******************************\n",
    "# Define the API endpoint and headers\n",
    "api_new_game = \"http://18.185.60.20:5005/new_game\"\n",
    "\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Start new game\n",
    "response = make_request(url = api_new_game, headers=headers)\n",
    "uuid = response.json().get('uuid')\n",
    "\n",
    "api_reset = \"http://18.185.60.20:5005/reset/\"+uuid\n",
    "api_step_url = \"http://18.185.60.20:5005/step/\"+uuid\n",
    "\n",
    "# Instantiate the custom environment\n",
    "env = MazeAPIEnv(api_step_url, headers,api_reset)\n",
    "\n",
    "\n",
    "\n",
    "obs, info = env.reset()\n",
    "n_steps = 10\n",
    "for _ in range(n_steps):\n",
    "    # Random action\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated:\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DEEP Q NETWORK#################\n",
    "\n",
    "# Define the API endpoint and headers\n",
    "api_new_game = \"http://18.185.60.20:5005/new_game\"\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Start new game\n",
    "response = make_request(url = api_new_game, headers=headers)\n",
    "uuid = response.json().get('uuid')\n",
    "\n",
    "api_reset = \"http://18.185.60.20:5005/reset/\"+uuid\n",
    "api_step_url = \"http://18.185.60.20:5005/step/\"+uuid\n",
    "\n",
    "# Instantiate the custom environment\n",
    "env = MazeAPIEnv(api_step_url, headers,api_reset)\n",
    "\n",
    "# Instantiate the DQN model with the custom policy\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[128, 256, 128]  # Hidden layers\n",
    ")\n",
    "\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=2,\n",
    "    exploration_fraction=0.2,\n",
    "    exploration_final_eps=0.05\n",
    ")\n",
    "# Train the agent\n",
    "logging.info(\"Starting the training process...\")\n",
    "callback = TrainingCallback()\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=5000,progress_bar=True,callback=callback)  # Adjust total_timesteps as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a01cc01a764426844b3fca9866a15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4        |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.036    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.394    |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4        |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | -0.244   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.0746   |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.212    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.58     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 518      |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | -0.0314  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.45     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 708      |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | -0.0431  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    value_loss         | 5.22     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 100       |\n",
      "|    ep_rew_mean        | 38.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 3         |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 817       |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -5.47e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -0.0143   |\n",
      "|    value_loss         | 0.0928    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 100       |\n",
      "|    ep_rew_mean        | 38.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 3         |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 1008      |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26     |\n",
      "|    explained_variance | -4.17e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.81      |\n",
      "|    value_loss         | 4.42      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 1116     |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.0113   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.682   |\n",
      "|    value_loss         | 0.3      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 1307     |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.000106 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.449    |\n",
      "|    value_loss         | 0.352    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 1416     |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 1.73e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    value_loss         | 3.7      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1253.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 689-752: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 435, in dispatch_shell\n",
      "    result = handler(self.shell_stream, idents, msg)\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\comm\\base_comm.py\", line 296, in comm_msg\n",
      "    comm.handle_msg(msg)\n",
      "  File \"C:\\Users\\DIMITRIS\\AppData\\Roaming\\Python\\Python310\\site-packages\\comm\\base_comm.py\", line 184, in handle_msg\n",
      "    logger.debug(\"handle_msg[%s](%s)\", self.comm_id, msg)\n",
      "Message: 'handle_msg[%s](%s)'\n",
      "Arguments: ('05a01cc01a764426844b3fca9866a15c', {'header': {'date': datetime.datetime(2024, 9, 11, 18, 10, 44, 106000, tzinfo=tzutc()), 'msg_id': 'ef98cae2-4425-4e55-b845-2e38196d9b28', 'msg_type': 'comm_msg', 'session': '3a15f948-c4f6-4b6a-8ecb-6ca155a30814', 'username': '4f912648-7106-4362-9819-79573974bbc1', 'version': '5.2'}, 'msg_id': 'ef98cae2-4425-4e55-b845-2e38196d9b28', 'msg_type': 'comm_msg', 'parent_header': {}, 'metadata': {}, 'content': {'comm_id': '05a01cc01a764426844b3fca9866a15c', 'data': {'method': 'update', 'state': {'outputs': [{'output_type': 'display_data', 'data': {'text/plain': '\\x1b[35m 100%\\x1b[0m \\x1b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[38;2;249;38;114m╸\\x1b[0m \\x1b[32m4,999/5,000 \\x1b[0m [ \\x1b[33m0:23:35\\x1b[0m < \\x1b[36m0:00:01\\x1b[0m , \\x1b[31m5 it/s\\x1b[0m ]\\n', 'text/html': '<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">4,999/5,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:23:35</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">5 it/s</span> ]\\n</pre>\\n'}, 'metadata': {}}]}, 'buffer_paths': []}}, 'buffers': []})\n"
     ]
    }
   ],
   "source": [
    "############### A2C ########################\n",
    "from stable_baselines3 import A2C\n",
    "# Define the API endpoint and headers\n",
    "api_new_game = \"http://18.185.60.20:5005/new_game\"\n",
    "\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Start new game\n",
    "response = make_request(url = api_new_game, headers=headers)\n",
    "uuid = response.json().get('uuid')\n",
    "\n",
    "api_reset = \"http://18.185.60.20:5005/reset/\"+uuid\n",
    "api_step_url = \"http://18.185.60.20:5005/step/\"+uuid\n",
    "\n",
    "# Instantiate the custom environment\n",
    "env = MazeAPIEnv(api_step_url, headers,api_reset)\n",
    "\n",
    "logging.info(\"Starting training\")\n",
    "\n",
    "# Instantiate the A2C model\n",
    "model = A2C('MlpPolicy', env, verbose=2)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=5000,progress_bar=True)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"a2c_maze_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode 1: Reward = 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 61\u001b[0m\n\u001b[0;32m     56\u001b[0m model \u001b[38;5;241m=\u001b[39m A2C(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m A2C\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma2c_maze_model.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m avg_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(model, env, num_episodes)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     22\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     26\u001b[0m total_rewards\u001b[38;5;241m.\u001b[39mappend(episode_reward)\n",
      "Cell \u001b[1;32mIn[5], line 60\u001b[0m, in \u001b[0;36mMazeAPIEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Send the action to the API\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     content \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(action)}\n\u001b[1;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_step_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m200\u001b[39m :\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror code in step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DIMITRIS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 61\u001b[0m, in \u001b[0;36mmake_request\u001b[1;34m(url, headers, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#raise http error for bad responses\u001b[39;00m\n\u001b[0;32m     59\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m---> 61\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, obs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "def evaluate_policy(model, env: gym.Env, num_episodes: int = 10):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model policy on the given environment.\n",
    "\n",
    "    :param model: Trained DQN model\n",
    "    :param env: Environment instance\n",
    "    :param num_episodes: Number of episodes to run for evaluation\n",
    "    :return: Average reward per episode\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "        print(f\"Episode {episode + 1}: Reward = {episode_reward}\")\n",
    "\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    return avg_reward\n",
    "\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "        \n",
    "    # Define the API endpoint and headers\n",
    "    api_new_game = \"http://18.185.60.20:5005/new_game\"\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Start new game\n",
    "    response = make_request(url = api_new_game, headers=headers)\n",
    "    uuid = response.json().get('uuid')\n",
    "\n",
    "    api_reset = \"http://18.185.60.20:5005/reset/\"+uuid\n",
    "    api_step_url = \"http://18.185.60.20:5005/step/\"+uuid\n",
    "\n",
    "    # Instantiate the custom environment\n",
    "    env = MazeAPIEnv(api_step_url, headers,api_reset)\n",
    "\n",
    "\n",
    "    # Instantiate the A2C model\n",
    "    model = A2C('MlpPolicy', env, verbose=2)\n",
    "\n",
    "\n",
    "    model = A2C.load('a2c_maze_model.zip')  # Load your trained model\n",
    "\n",
    "    avg_reward = evaluate_policy(model, env, num_episodes=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
